{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb0cd9-f811-4de9-a519-f257e3233056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6934a95d-84d2-489d-9d02-e679c98ce21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from painn_flops import PaiNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4681d9d5-1209-4ce8-8e14-63783da863d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from schnetpack.nn.radial import GaussianRBF\n",
    "from schnetpack.nn.cutoff import CosineCutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0023789d-c1e1-48a0-ae2d-70628ac0fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  1,  1,  1,  1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('tob9.npz')\n",
    "z = data[\"z\"]\n",
    "z = torch.from_numpy(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e2a12c9-6b57-48fe-b241-6670d6188ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                            | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|██████████                                                                                          | 1/10 [00:00<00:01,  8.99it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded properties:\n",
      " _idx\n",
      " energy\n",
      " forces\n",
      " _n_atoms\n",
      " _atomic_numbers\n",
      " _positions\n",
      " _cell\n",
      " _pbc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from schnetpack.data import AtomsDataModule\n",
    "import schnetpack.transform as trn\n",
    "from schnetpack.datasets import MD17\n",
    "\n",
    "\n",
    "\n",
    "tob9_data = AtomsDataModule(\n",
    "    datapath = \"./tob9.db\",\n",
    "    #molecule='tob9',\n",
    "    batch_size=10,\n",
    "    num_train=100,\n",
    "    num_val=50,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=4.),\n",
    "        trn.RemoveOffsets(\"energy\", remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    ")\n",
    "tob9_data.prepare_data()\n",
    "tob9_data.setup()\n",
    "\n",
    "properties = tob9_data.dataset[0]\n",
    "print('Loaded properties:\\n', *['{:s}\\n'.format(i) for i in properties.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c34ebeab-d89c-4595-90d0-9903536f91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4133742592.0, 25557032.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "from thop import profile\n",
    "model = resnet50()\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "macs,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35151261-c57d-4122-ada2-63f25a88a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PaiNN(n_atom_basis=128,n_interactions=3,radial_basis=GaussianRBF(n_rbf = 20, cutoff = 4.0),cutoff_fn=CosineCutoff(cutoff = 4.0))\n",
    "input = {'z': properties[\"_atomic_numbers\"], 'rij': torch.randn(500,3), 'idxi': torch.randint(0,61,(1,500))[0], 'idxj': torch.randint(0,61,(1,500))[0]}\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "macs,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fec586-e8d6-4d7f-9b4e-217d48950ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AtomsDataError",
     "evalue": "Dataset already exists: ./uracil.db",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAtomsDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     atoms_list\u001b[38;5;241m.\u001b[39mappend(ats)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#%rm './ethanol.db'\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mASEAtomsData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./uracil.db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_unit_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menergy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkcal/mol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkcal/mol/Ang\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m new_dataset\u001b[38;5;241m.\u001b[39madd_systems(property_list, atoms_list)\n",
      "File \u001b[0;32m~/anaconda3/envs/schnet/lib/python3.8/site-packages/schnetpack/data/atoms.py:437\u001b[0m, in \u001b[0;36mASEAtomsData.create\u001b[0;34m(datapath, distance_unit, property_unit_dict, atomrefs, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AtomsDataError(\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid datapath! Please make sure to add the file extension \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour dbpath.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(datapath):\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AtomsDataError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset already exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatapath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m atomrefs \u001b[38;5;241m=\u001b[39m atomrefs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m connect(datapath) \u001b[38;5;28;01mas\u001b[39;00m conn:\n",
      "\u001b[0;31mAtomsDataError\u001b[0m: Dataset already exists: ./uracil.db"
     ]
    }
   ],
   "source": [
    "from ase import Atoms\n",
    "import numpy as np\n",
    "from schnetpack.data import ASEAtomsData\n",
    "\n",
    "# load atoms from npz file. Here, we only parse the first 10 molecules\n",
    "data = np.load('./md17_uracil.npz')\n",
    "\n",
    "numbers = data[\"z\"]\n",
    "atoms_list = []\n",
    "property_list = []\n",
    "for positions, energies, forces in zip(data[\"R\"], data[\"E\"], data[\"F\"]):\n",
    "    ats = Atoms(positions=positions, numbers=numbers)\n",
    "    properties = {'energy': energies, 'forces': forces}\n",
    "    property_list.append(properties)\n",
    "    atoms_list.append(ats)\n",
    "\n",
    "#%rm './ethanol.db'\n",
    "new_dataset = ASEAtomsData.create(\n",
    "    './uracil.db',\n",
    "    distance_unit='Ang',\n",
    "    property_unit_dict={'energy':'kcal/mol', 'forces':'kcal/mol/Ang'}\n",
    ")\n",
    "new_dataset.add_systems(property_list, atoms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b17aa60-50a4-4c35-8c72-c04f2dafbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import schnetpack as spk\n",
    "import schnetpack.transform as trn\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "forcetut = './forcetut'\n",
    "if not os.path.exists(forcetut):\n",
    "    os.makedirs(forcetut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0af79df-37b9-4066-bc75-a6527607e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Split file was given, but `num_train (1000) != len(train_idx)` (100)!\n",
      "WARNING:root:Split file was given, but `num_val (1000) != len(val_idx)` (50)!\n",
      "100%|█████████████████████████████████████████████████████| 10/10 [00:00<00:00, 47.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from schnetpack.datasets import MD17\n",
    "\n",
    "ethanol_data = MD17(\n",
    "    os.path.join(forcetut,'u.db'),\n",
    "    molecule='uracil',\n",
    "    batch_size=10,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(MD17.energy, remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    ")\n",
    "ethanol_data.prepare_data()\n",
    "ethanol_data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971880c0-61cb-4eb0-b797-84cc9aae8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4883c9-7bd5-4c3d-9be9-0d5abbb915db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_energy = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=MD17.energy)\n",
    "pred_forces = spk.atomistic.Forces(energy_key=MD17.energy, force_key=MD17.forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d8d0b8-985f-49fb-95a2-34b22a6bfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_energy, pred_forces],\n",
    "    postprocessors=[\n",
    "        trn.CastTo64(),\n",
    "        trn.AddOffsets(MD17.energy, add_mean=True, add_atomrefs=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2263a15-7cc9-4a61-be58-e74e018d80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_energy = spk.task.ModelOutput(\n",
    "    name=MD17.energy,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.01,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "output_forces = spk.task.ModelOutput(\n",
    "    name=MD17.forces,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.99,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32e21ffb-d04b-44a1-8a95-17d762c25514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zkm/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy, output_forces],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba94e4c4-a95f-48d2-8bfd-8726d6a80e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-04-01 18:00:34.631035: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 18:00:35.504935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                  | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zkm/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=103` in the `DataLoader` to improve performance.\n",
      "/home/zkm/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/zkm/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=103` in the `DataLoader` to improve performance.\n",
      "/home/zkm/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05deb6d09a64232b57c11b67e741f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=forcetut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(forcetut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=forcetut,\n",
    "    max_epochs=5, # for testing, we restrict the number of epochs\n",
    ")\n",
    "trainer.fit(task, datamodule=ethanol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f66da5-1dbf-42a3-9fe1-41272863c9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Split file was given, but `num_train (1000) != len(train_idx)` (100)!\n",
      "WARNING:root:Split file was given, but `num_val (1000) != len(val_idx)` (50)!\n",
      "100%|█████████████████████████████████████████████████████| 10/10 [00:00<00:00, 52.58it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "initialize_derivatives() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m pairwise_distance \u001b[38;5;241m=\u001b[39m spk\u001b[38;5;241m.\u001b[39matomistic\u001b[38;5;241m.\u001b[39mPairwiseDistances()\n\u001b[1;32m     39\u001b[0m input_modules \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([pairwise_distance])\n\u001b[0;32m---> 40\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mAtomisticModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m input_modules:\n\u001b[1;32m     42\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m m(inputs)\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize_derivatives() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import schnetpack as spk\n",
    "import torchmetrics\n",
    "import schnetpack.transform as trn\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from schnetpack.datasets import MD17\n",
    "from schnetpack.model import AtomisticModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "forcetut = './forcetut'\n",
    "if not os.path.exists(forcetut):\n",
    "    os.makedirs(forcetut)\n",
    "\n",
    "ethanol_data = MD17(\n",
    "    os.path.join(forcetut,'u.db'),\n",
    "    molecule='uracil',\n",
    "    batch_size=10,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(MD17.energy, remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=True, # set to false, when not using a GPU\n",
    ")\n",
    "ethanol_data.prepare_data()\n",
    "ethanol_data.setup()\n",
    "\n",
    "inputs = ethanol_data\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances()\n",
    "input_modules = nn.ModuleList([pairwise_distance])\n",
    "inputs = AtomisticModel.initialize_derivatives(inputs)\n",
    "for m in input_modules:\n",
    "    inputs = m(inputs)\n",
    "inputs = self.representation(inputs)\n",
    "postprocessors=[\n",
    "    trn.CastTo64(),\n",
    "    trn.AddOffsets(MD17.energy, add_mean=True, add_atomrefs=False)\n",
    "]\n",
    "inputs = self.postprocess(inputs)\n",
    "#Dict[str,torch.Tensor]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schnet",
   "language": "python",
   "name": "schnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
