{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\r\n",
    "import os\r\n",
    "import logging\r\n",
    "\r\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\r\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"1\"\r\n",
    "\r\n",
    "logger = logging.getLogger()\r\n",
    "logger.handlers = []\r\n",
    "ch = logging.StreamHandler()\r\n",
    "formatter = logging.Formatter(\r\n",
    "    fmt=\"%(asctime)s (%(levelname)s): %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\r\n",
    ")\r\n",
    "ch.setFormatter(formatter)\r\n",
    "logger.addHandler(ch)\r\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import yaml\r\n",
    "import string\r\n",
    "import ast\r\n",
    "import random\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "from gemnet.model.gemnet import GemNet\r\n",
    "from gemnet.training.trainer import Trainer\r\n",
    "from gemnet.training.metrics import Metrics, BestMetrics\r\n",
    "from gemnet.training.data_container import DataContainer\r\n",
    "from gemnet.training.data_provider import DataProvider\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as c:\r\n",
    "    config = yaml.safe_load(c)\r\n",
    "    \r\n",
    "# For strings that yaml doesn't parse (e.g. None)\r\n",
    "for key, val in config.items():\r\n",
    "    if type(val) is str:\r\n",
    "        try:\r\n",
    "            config[key] = ast.literal_eval(val)\r\n",
    "        except (ValueError, SyntaxError):\r\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spherical = config[\"num_spherical\"]\r\n",
    "num_radial = config[\"num_radial\"]\r\n",
    "num_blocks = config[\"num_blocks\"]\r\n",
    "emb_size_atom = config[\"emb_size_atom\"]\r\n",
    "emb_size_edge = config[\"emb_size_edge\"]\r\n",
    "emb_size_trip = config[\"emb_size_trip\"]\r\n",
    "emb_size_quad = config[\"emb_size_quad\"]\r\n",
    "emb_size_rbf = config[\"emb_size_rbf\"]\r\n",
    "emb_size_cbf = config[\"emb_size_cbf\"]\r\n",
    "emb_size_sbf = config[\"emb_size_sbf\"]\r\n",
    "num_before_skip = config[\"num_before_skip\"]\r\n",
    "num_after_skip = config[\"num_after_skip\"]\r\n",
    "num_concat = config[\"num_concat\"]\r\n",
    "num_atom = config[\"num_atom\"]\r\n",
    "emb_size_bil_quad = config[\"emb_size_bil_quad\"]\r\n",
    "emb_size_bil_trip = config[\"emb_size_bil_trip\"]\r\n",
    "triplets_only = config[\"triplets_only\"]\r\n",
    "forces_coupled = config[\"forces_coupled\"]\r\n",
    "direct_forces = config[\"direct_forces\"]\r\n",
    "mve = config[\"mve\"]\r\n",
    "cutoff = config[\"cutoff\"]\r\n",
    "int_cutoff = config[\"int_cutoff\"]\r\n",
    "envelope_exponent = config[\"envelope_exponent\"]\r\n",
    "extensive = config[\"extensive\"]\r\n",
    "output_init = config[\"output_init\"]\r\n",
    "scale_file = config[\"scale_file\"]\r\n",
    "data_seed = config[\"data_seed\"]\r\n",
    "dataset = config[\"dataset\"]\r\n",
    "val_dataset = config[\"val_dataset\"]\r\n",
    "num_train = config[\"num_train\"]\r\n",
    "num_val = config[\"num_val\"]\r\n",
    "logdir = config[\"logdir\"]\r\n",
    "loss = config[\"loss\"]\r\n",
    "tfseed = config[\"tfseed\"]\r\n",
    "num_steps = config[\"num_steps\"]\r\n",
    "rho_force = config[\"rho_force\"]\r\n",
    "ema_decay = config[\"ema_decay\"]\r\n",
    "weight_decay = config[\"weight_decay\"]\r\n",
    "grad_clip_max = config[\"grad_clip_max\"]\r\n",
    "agc = config[\"agc\"]\r\n",
    "decay_patience = config[\"decay_patience\"]\r\n",
    "decay_factor = config[\"decay_factor\"]\r\n",
    "decay_cooldown = config[\"decay_cooldown\"]\r\n",
    "batch_size = config[\"batch_size\"]\r\n",
    "evaluation_interval = config[\"evaluation_interval\"]\r\n",
    "patience = config[\"patience\"]\r\n",
    "save_interval = config[\"save_interval\"]\r\n",
    "learning_rate = config[\"learning_rate\"]\r\n",
    "warmup_steps = config[\"warmup_steps\"]\r\n",
    "decay_steps = config[\"decay_steps\"]\r\n",
    "decay_rate = config[\"decay_rate\"]\r\n",
    "staircase = config[\"staircase\"]\r\n",
    "restart = config[\"restart\"]\r\n",
    "comment = config[\"comment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 17:44:06 (INFO): Start training\n",
      "2024-03-30 17:44:06 (INFO): Available GPUs: 1\n",
      "2024-03-30 17:44:06 (INFO): CUDA Available: True\n",
      "2024-03-30 17:44:06 (INFO): Directory: logs/20240330_174406_t7cjUa_tob14_gemnet.npz_GemNet\n",
      "2024-03-30 17:44:06 (INFO): Create directories\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(tfseed)\r\n",
    "\r\n",
    "logging.info(\"Start training\")\r\n",
    "num_gpus = torch.cuda.device_count()\r\n",
    "cuda_available = torch.cuda.is_available()\r\n",
    "logging.info(f\"Available GPUs: {num_gpus}\")\r\n",
    "logging.info(f\"CUDA Available: {cuda_available}\")\r\n",
    "if num_gpus == 0:\r\n",
    "    logging.warning(\"No GPUs were found. Training is run on CPU!\")\r\n",
    "if not cuda_available:\r\n",
    "    logging.warning(\"CUDA unavailable. Training is run on CPU!\")\r\n",
    "\r\n",
    "# Used for creating a \"unique\" id for a run (almost impossible to generate the same twice)\r\n",
    "def id_generator(\r\n",
    "    size=6, chars=string.ascii_uppercase + string.ascii_lowercase + string.digits\r\n",
    "):\r\n",
    "    return \"\".join(random.SystemRandom().choice(chars) for _ in range(size))\r\n",
    "\r\n",
    "# A unique directory name is created for this run based on the input\r\n",
    "if (restart is None) or (restart == \"None\"):\r\n",
    "    directory = (\r\n",
    "        logdir\r\n",
    "        + \"/\"\r\n",
    "        + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n",
    "        + \"_\"\r\n",
    "        + id_generator()\r\n",
    "        + \"_\"\r\n",
    "        + os.path.basename(dataset)\r\n",
    "        + \"_\"\r\n",
    "        + str(comment)\r\n",
    "    )\r\n",
    "else:\r\n",
    "    directory = restart\r\n",
    "\r\n",
    "logging.info(f\"Directory: {directory}\")\r\n",
    "logging.info(\"Create directories\")\r\n",
    "\r\n",
    "if not os.path.exists(directory):\r\n",
    "    os.makedirs(directory, exist_ok=True)\r\n",
    "\r\n",
    "best_dir = os.path.join(directory, \"best\")\r\n",
    "if not os.path.exists(best_dir):\r\n",
    "    os.makedirs(best_dir)\r\n",
    "log_dir = os.path.join(directory, \"logs\")\r\n",
    "if not os.path.exists(log_dir):\r\n",
    "    os.makedirs(log_dir)\r\n",
    "\r\n",
    "extension = \".pth\"\r\n",
    "log_path_model = f\"{log_dir}/model{extension}\"\r\n",
    "log_path_training = f\"{log_dir}/training{extension}\"\r\n",
    "best_path_model = f\"{best_dir}/model{extension}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 17:44:06 (INFO): Initialize model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GemNet(\n",
       "  (rbf_basis): BesselBasisLayer(\n",
       "    (envelope): Envelope()\n",
       "  )\n",
       "  (cbf_basis): SphericalBasisLayer(\n",
       "    (envelope): Envelope()\n",
       "  )\n",
       "  (sbf_basis): TensorBasisLayer(\n",
       "    (envelope): Envelope()\n",
       "  )\n",
       "  (cbf_basis3): SphericalBasisLayer(\n",
       "    (envelope): Envelope()\n",
       "  )\n",
       "  (mlp_rbf4): Dense(\n",
       "    (linear): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (_activation): Identity()\n",
       "  )\n",
       "  (mlp_cbf4): Dense(\n",
       "    (linear): Linear(in_features=42, out_features=16, bias=False)\n",
       "    (_activation): Identity()\n",
       "  )\n",
       "  (mlp_sbf4): EfficientInteractionDownProjection()\n",
       "  (mlp_rbf3): Dense(\n",
       "    (linear): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (_activation): Identity()\n",
       "  )\n",
       "  (mlp_cbf3): EfficientInteractionDownProjection()\n",
       "  (mlp_rbf_h): Dense(\n",
       "    (linear): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (_activation): Identity()\n",
       "  )\n",
       "  (mlp_rbf_out): Dense(\n",
       "    (linear): Linear(in_features=6, out_features=16, bias=False)\n",
       "    (_activation): Identity()\n",
       "  )\n",
       "  (atom_emb): AtomEmbedding(\n",
       "    (embeddings): Embedding(93, 128)\n",
       "  )\n",
       "  (edge_emb): EdgeEmbedding(\n",
       "    (dense): Dense(\n",
       "      (linear): Linear(in_features=262, out_features=128, bias=False)\n",
       "      (_activation): ScaledSiLU(\n",
       "        (_activation): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_blocks): ModuleList(\n",
       "    (0): OutputBlock(\n",
       "      (dense_rbf): Dense(\n",
       "        (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "      (scale_sum): ScalingFactor()\n",
       "      (layers): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (seq_energy): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_energy): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): OutputBlock(\n",
       "      (dense_rbf): Dense(\n",
       "        (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "      (scale_sum): ScalingFactor()\n",
       "      (layers): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (seq_energy): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_energy): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): OutputBlock(\n",
       "      (dense_rbf): Dense(\n",
       "        (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "      (scale_sum): ScalingFactor()\n",
       "      (layers): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (seq_energy): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_energy): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): OutputBlock(\n",
       "      (dense_rbf): Dense(\n",
       "        (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "      (scale_sum): ScalingFactor()\n",
       "      (layers): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (seq_energy): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_energy): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): OutputBlock(\n",
       "      (dense_rbf): Dense(\n",
       "        (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "      (scale_sum): ScalingFactor()\n",
       "      (layers): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (seq_energy): ModuleList(\n",
       "        (0): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out_energy): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (_activation): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (int_blocks): ModuleList(\n",
       "    (0): InteractionBlock(\n",
       "      (dense_ca): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (_activation): ScaledSiLU(\n",
       "          (_activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (quad_interaction): QuadrupletInteraction(\n",
       "        (dense_db): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=32, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_cbf): ScalingFactor()\n",
       "        (mlp_sbf): EfficientInteractionBilinear()\n",
       "        (scale_sbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trip_interaction): TripletInteraction(\n",
       "        (dense_ba): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): EfficientInteractionBilinear()\n",
       "        (scale_cbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=64, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_before_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_after_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (atom_update): AtomUpdateBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScalingFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (concat_layer): EdgeEmbedding(\n",
       "        (dense): Dense(\n",
       "          (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual_m): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): InteractionBlock(\n",
       "      (dense_ca): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (_activation): ScaledSiLU(\n",
       "          (_activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (quad_interaction): QuadrupletInteraction(\n",
       "        (dense_db): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=32, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_cbf): ScalingFactor()\n",
       "        (mlp_sbf): EfficientInteractionBilinear()\n",
       "        (scale_sbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trip_interaction): TripletInteraction(\n",
       "        (dense_ba): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): EfficientInteractionBilinear()\n",
       "        (scale_cbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=64, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_before_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_after_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (atom_update): AtomUpdateBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScalingFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (concat_layer): EdgeEmbedding(\n",
       "        (dense): Dense(\n",
       "          (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual_m): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InteractionBlock(\n",
       "      (dense_ca): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (_activation): ScaledSiLU(\n",
       "          (_activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (quad_interaction): QuadrupletInteraction(\n",
       "        (dense_db): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=32, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_cbf): ScalingFactor()\n",
       "        (mlp_sbf): EfficientInteractionBilinear()\n",
       "        (scale_sbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trip_interaction): TripletInteraction(\n",
       "        (dense_ba): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): EfficientInteractionBilinear()\n",
       "        (scale_cbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=64, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_before_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_after_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (atom_update): AtomUpdateBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScalingFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (concat_layer): EdgeEmbedding(\n",
       "        (dense): Dense(\n",
       "          (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual_m): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InteractionBlock(\n",
       "      (dense_ca): Dense(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (_activation): ScaledSiLU(\n",
       "          (_activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (quad_interaction): QuadrupletInteraction(\n",
       "        (dense_db): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=32, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_cbf): ScalingFactor()\n",
       "        (mlp_sbf): EfficientInteractionBilinear()\n",
       "        (scale_sbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (trip_interaction): TripletInteraction(\n",
       "        (dense_ba): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (mlp_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_rbf): ScalingFactor()\n",
       "        (mlp_cbf): EfficientInteractionBilinear()\n",
       "        (scale_cbf_sum): ScalingFactor()\n",
       "        (down_projection): Dense(\n",
       "          (linear): Linear(in_features=128, out_features=64, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ca): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (up_projection_ac): Dense(\n",
       "          (linear): Linear(in_features=64, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_before_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_after_skip): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (atom_update): AtomUpdateBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScalingFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (concat_layer): EdgeEmbedding(\n",
       "        (dense): Dense(\n",
       "          (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual_m): ModuleList(\n",
       "        (0): ResidualLayer(\n",
       "          (dense_mlp): Sequential(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Dense(\n",
       "              (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info(\"Initialize model\")\r\n",
    "model = GemNet(\r\n",
    "    num_spherical=num_spherical,\r\n",
    "    num_radial=num_radial,\r\n",
    "    num_blocks=num_blocks,\r\n",
    "    emb_size_atom=emb_size_atom,\r\n",
    "    emb_size_edge=emb_size_edge,\r\n",
    "    emb_size_trip=emb_size_trip,\r\n",
    "    emb_size_quad=emb_size_quad,\r\n",
    "    emb_size_rbf=emb_size_rbf,\r\n",
    "    emb_size_cbf=emb_size_cbf,\r\n",
    "    emb_size_sbf=emb_size_sbf,\r\n",
    "    num_before_skip=num_before_skip,\r\n",
    "    num_after_skip=num_after_skip,\r\n",
    "    num_concat=num_concat,\r\n",
    "    num_atom=num_atom,\r\n",
    "    emb_size_bil_quad=emb_size_bil_quad,\r\n",
    "    emb_size_bil_trip=emb_size_bil_trip,\r\n",
    "    num_targets=2 if mve else 1,\r\n",
    "    triplets_only=triplets_only,\r\n",
    "    direct_forces=direct_forces,\r\n",
    "    forces_coupled=forces_coupled,\r\n",
    "    cutoff=cutoff,\r\n",
    "    int_cutoff=int_cutoff,\r\n",
    "    envelope_exponent=envelope_exponent,\r\n",
    "    activation=\"swish\",\r\n",
    "    extensive=extensive,\r\n",
    "    output_init=output_init,\r\n",
    "    scale_file=scale_file,\r\n",
    ")\r\n",
    "# push to GPU if available\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 17:44:57 (INFO): Load dataset\n",
      "2024-03-30 17:44:57 (INFO): Training data size: 950\n",
      "2024-03-30 17:44:58 (INFO): Validation data size: 50\n"
     ]
    }
   ],
   "source": [
    "train = {}\r\n",
    "validation = {}\r\n",
    "\r\n",
    "logging.info(\"Load dataset\")\r\n",
    "data_container = DataContainer(\r\n",
    "    dataset, cutoff=cutoff, int_cutoff=int_cutoff, triplets_only=triplets_only\r\n",
    ")\r\n",
    "\r\n",
    "if val_dataset is not None:\r\n",
    "    # Initialize DataProvider\r\n",
    "    if num_train == 0:\r\n",
    "        num_train = len(data_container)\r\n",
    "    logging.info(f\"Training data size: {num_train}\")\r\n",
    "    data_provider = DataProvider(\r\n",
    "        data_container,\r\n",
    "        num_train,\r\n",
    "        0,\r\n",
    "        batch_size,\r\n",
    "        seed=data_seed,\r\n",
    "        shuffle=True,\r\n",
    "        random_split=True,\r\n",
    "    )\r\n",
    "\r\n",
    "    # Initialize validation datasets\r\n",
    "    val_data_container = DataContainer(\r\n",
    "        val_dataset,\r\n",
    "        cutoff=cutoff,\r\n",
    "        int_cutoff=int_cutoff,\r\n",
    "        triplets_only=triplets_only,\r\n",
    "    )\r\n",
    "    if num_val == 0:\r\n",
    "        num_val = len(val_data_container)\r\n",
    "    logging.info(f\"Validation data size: {num_val}\")\r\n",
    "    val_data_provider = DataProvider(\r\n",
    "        val_data_container,\r\n",
    "        0,\r\n",
    "        num_val,\r\n",
    "        batch_size,\r\n",
    "        seed=data_seed,\r\n",
    "        shuffle=True,\r\n",
    "        random_split=True,\r\n",
    "    )\r\n",
    "else:\r\n",
    "    # Initialize DataProvider (splits dataset into 3 sets based on data_seed and provides tf.datasets)\r\n",
    "    logging.info(f\"Training data size: {num_train}\")\r\n",
    "    logging.info(f\"Validation data size: {num_val}\")\r\n",
    "    assert num_train > 0\r\n",
    "    assert num_val > 0\r\n",
    "    data_provider = DataProvider(\r\n",
    "        data_container,\r\n",
    "        num_train,\r\n",
    "        num_val,\r\n",
    "        batch_size,\r\n",
    "        seed=data_seed,\r\n",
    "        shuffle=True,\r\n",
    "        random_split=True,\r\n",
    "    )\r\n",
    "    val_data_provider = data_provider\r\n",
    "\r\n",
    "# Initialize datasets\r\n",
    "train[\"dataset_iter\"] = data_provider.get_dataset(\"train\")\r\n",
    "validation[\"dataset_iter\"] = val_data_provider.get_dataset(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 17:44:58 (INFO): Prepare training\n",
      "2024-03-30 17:44:58 (INFO): Freshly initialize model\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Prepare training\")\r\n",
    "# Initialize trainer\r\n",
    "trainer = Trainer(\r\n",
    "    model,\r\n",
    "    learning_rate=learning_rate,\r\n",
    "    decay_steps=decay_steps,\r\n",
    "    decay_rate=decay_rate,\r\n",
    "    warmup_steps=warmup_steps,\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    ema_decay=ema_decay,\r\n",
    "    decay_patience=decay_patience,\r\n",
    "    decay_factor=decay_factor,\r\n",
    "    decay_cooldown=decay_cooldown,\r\n",
    "    grad_clip_max=grad_clip_max,\r\n",
    "    rho_force=rho_force,\r\n",
    "    mve=mve,\r\n",
    "    loss=loss,\r\n",
    "    staircase=staircase,\r\n",
    "    agc=agc,\r\n",
    ")\r\n",
    "\r\n",
    "# Initialize metrics\r\n",
    "train[\"metrics\"] = Metrics(\"train\", trainer.tracked_metrics)\r\n",
    "validation[\"metrics\"] = Metrics(\"val\", trainer.tracked_metrics)\r\n",
    "\r\n",
    "# Save/load best recorded loss (only the best model is saved)\r\n",
    "metrics_best = BestMetrics(best_dir, validation[\"metrics\"])\r\n",
    "\r\n",
    "# Set up checkpointing\r\n",
    "# Restore latest checkpoint\r\n",
    "if os.path.exists(log_path_model):\r\n",
    "    logging.info(\"Restoring model and trainer\")\r\n",
    "    model_checkpoint = torch.load(log_path_model)\r\n",
    "    model.load_state_dict(model_checkpoint[\"model\"])\r\n",
    "\r\n",
    "    train_checkpoint = torch.load(log_path_training)\r\n",
    "    trainer.load_state_dict(train_checkpoint[\"trainer\"])\r\n",
    "    # restore the best saved results\r\n",
    "    metrics_best.restore()\r\n",
    "    logging.info(f\"Restored best metrics: {metrics_best.loss}\")\r\n",
    "    step_init = int(train_checkpoint[\"step\"])\r\n",
    "else:\r\n",
    "    logging.info(\"Freshly initialize model\")\r\n",
    "    metrics_best.inititalize()\r\n",
    "    step_init = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 19:08:19 (INFO): 7500/237500 (epoch 31): loss: train=0.711828, val=0.469276; energy_mae: train=39.135704, val=6.236775; force_mae: train=0.338482, val=0.233707; force_rmse: train=0.673366, val=0.463503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     summary_writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr, global_step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform training step\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save progress\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m save_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/MLIP/GemNet/gemnet/configs/CSH/large_set/tob14/gemnet/training/trainer.py:331\u001b[0m, in \u001b[0;36mTrainer.train_on_batch\u001b[0;34m(self, dataset_iter, metrics)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# push to GPU if available\u001b[39;00m\n\u001b[1;32m    329\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict2device(inputs), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict2device(targets)\n\u001b[0;32m--> 331\u001b[0m mean_energy, var_energy, mean_forces, var_forces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmve:\n\u001b[1;32m    334\u001b[0m     energy_nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nll(targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m\"\u001b[39m], mean_energy, var_energy)\n",
      "File \u001b[0;32m~/MLIP/GemNet/gemnet/configs/CSH/large_set/tob14/gemnet/training/trainer.py:299\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m--> 299\u001b[0m     energy, forces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmve:\n\u001b[1;32m    302\u001b[0m         mean_energy \u001b[38;5;241m=\u001b[39m energy[:, :\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/gemnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLIP/GemNet/gemnet/configs/CSH/large_set/tob14/gemnet/model/gemnet.py:611\u001b[0m, in \u001b[0;36mGemNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         F_j \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(forces, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m         F_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    613\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m E_a, F_j\n",
      "File \u001b[0;32m~/anaconda3/envs/gemnet/lib/python3.10/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary_writer = SummaryWriter(log_dir)\r\n",
    "steps_per_epoch = int(np.ceil(num_train / batch_size))\r\n",
    "\r\n",
    "for step in range(step_init + 1, num_steps + 1):\r\n",
    "\r\n",
    "    # keep track of the learning rate\r\n",
    "    if step % 10 == 0:\r\n",
    "        lr = trainer.schedulers[0].get_last_lr()[0]\r\n",
    "        summary_writer.add_scalar(\"lr\", lr, global_step=step)\r\n",
    "\r\n",
    "    # Perform training step\r\n",
    "    trainer.train_on_batch(train[\"dataset_iter\"], train[\"metrics\"])\r\n",
    "\r\n",
    "    # Save progress\r\n",
    "    if step % save_interval == 0:\r\n",
    "        torch.save({\"model\": model.state_dict()}, log_path_model)\r\n",
    "        torch.save(\r\n",
    "            {\"trainer\": trainer.state_dict(), \"step\": step}, log_path_training\r\n",
    "        )\r\n",
    "\r\n",
    "    # Check performance on the validation set\r\n",
    "    if step % evaluation_interval == 0:\r\n",
    "\r\n",
    "        # Save backup variables and load averaged variables\r\n",
    "        trainer.save_variable_backups()\r\n",
    "        trainer.load_averaged_variables()\r\n",
    "\r\n",
    "        # Compute averages\r\n",
    "        for i in range(int(np.ceil(num_val / batch_size))):\r\n",
    "            trainer.test_on_batch(validation[\"dataset_iter\"], validation[\"metrics\"])\r\n",
    "\r\n",
    "        # Update and save best result\r\n",
    "        if validation[\"metrics\"].loss < metrics_best.loss:\r\n",
    "            metrics_best.update(step, validation[\"metrics\"])\r\n",
    "            torch.save(model.state_dict(), best_path_model)\r\n",
    "\r\n",
    "        # write to summary writer\r\n",
    "        metrics_best.write(summary_writer, step)\r\n",
    "\r\n",
    "        epoch = step // steps_per_epoch\r\n",
    "        train_metrics_res = train[\"metrics\"].result(append_tag=False)\r\n",
    "        val_metrics_res = validation[\"metrics\"].result(append_tag=False)\r\n",
    "        metrics_strings = [\r\n",
    "            f\"{key}: train={train_metrics_res[key]:.6f}, val={val_metrics_res[key]:.6f}\"\r\n",
    "            for key in validation[\"metrics\"].keys\r\n",
    "        ]\r\n",
    "        logging.info(\r\n",
    "            f\"{step}/{num_steps} (epoch {epoch}): \" + \"; \".join(metrics_strings)\r\n",
    "        )\r\n",
    "\r\n",
    "        # decay learning rate on plateau\r\n",
    "        trainer.decay_maybe(validation[\"metrics\"].loss)\r\n",
    "\r\n",
    "        train[\"metrics\"].write(summary_writer, step)\r\n",
    "        validation[\"metrics\"].write(summary_writer, step)\r\n",
    "        train[\"metrics\"].reset_states()\r\n",
    "        validation[\"metrics\"].reset_states()\r\n",
    "\r\n",
    "        # Restore backup variables\r\n",
    "        trainer.restore_variable_backups()\r\n",
    "\r\n",
    "        # early stopping\r\n",
    "        if step - metrics_best.step > patience * evaluation_interval:\r\n",
    "            break\r\n",
    "\r\n",
    "result = {key + \"_best\": val for key, val in metrics_best.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in metrics_best.items():\r\n",
    "    print(f\"{key}: {val}\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/zkm/anaconda3/envs/gemnet:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                  2_kmp_llvm    conda-forge\n",
      "absl-py                   2.1.0                    pypi_0    pypi\n",
      "anyio                     4.3.0                    pypi_0    pypi\n",
      "argon2-cffi               23.1.0                   pypi_0    pypi\n",
      "arrow                     1.3.0                    pypi_0    pypi\n",
      "ase                       3.22.1                   pypi_0    pypi\n",
      "asttokens                 2.4.1                    pypi_0    pypi\n",
      "astunparse                1.6.3                    pypi_0    pypi\n",
      "async-lru                 2.0.4                    pypi_0    pypi\n",
      "attrs                     23.2.0                   pypi_0    pypi\n",
      "babel                     2.14.0                   pypi_0    pypi\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "beautifulsoup4            4.12.3                   pypi_0    pypi\n",
      "blas                      2.121                       mkl    conda-forge\n",
      "blas-devel                3.9.0            21_linux64_mkl    conda-forge\n",
      "bleach                    6.1.0                    pypi_0    pypi\n",
      "bzip2                     1.0.8                hd590300_5    conda-forge\n",
      "ca-certificates           2024.3.11            h06a4308_0  \n",
      "certifi                   2024.2.2         py39h06a4308_0  \n",
      "charset-normalizer        3.3.2                    pypi_0    pypi\n",
      "comm                      0.2.2                    pypi_0    pypi\n",
      "contourpy                 1.2.0                    pypi_0    pypi\n",
      "cudatoolkit               11.3.1              hb98b00a_13    conda-forge\n",
      "cycler                    0.12.1                   pypi_0    pypi\n",
      "debugpy                   1.8.1                    pypi_0    pypi\n",
      "decorator                 5.1.1              pyhd3eb1b0_0  \n",
      "exceptiongroup            1.2.0            py39h06a4308_0  \n",
      "executing                 2.0.1                    pypi_0    pypi\n",
      "fastjsonschema            2.19.1                   pypi_0    pypi\n",
      "ffmpeg                    4.3                  hf484d3e_0    pytorch\n",
      "flatbuffers               24.3.7                   pypi_0    pypi\n",
      "fonttools                 4.50.0                   pypi_0    pypi\n",
      "fqdn                      1.5.1                    pypi_0    pypi\n",
      "freetype                  2.12.1               h267a509_2    conda-forge\n",
      "gast                      0.5.4                    pypi_0    pypi\n",
      "gmp                       6.3.0                h59595ed_1    conda-forge\n",
      "gnutls                    3.6.13               h85f3911_1    conda-forge\n",
      "google-pasta              0.2.0                    pypi_0    pypi\n",
      "grpcio                    1.62.1                   pypi_0    pypi\n",
      "h11                       0.14.0                   pypi_0    pypi\n",
      "h5py                      3.10.0                   pypi_0    pypi\n",
      "httpcore                  1.0.4                    pypi_0    pypi\n",
      "httpx                     0.27.0                   pypi_0    pypi\n",
      "icu                       73.2                 h59595ed_0    conda-forge\n",
      "idna                      3.6                      pypi_0    pypi\n",
      "importlib-metadata        7.1.0                    pypi_0    pypi\n",
      "importlib-resources       6.3.2                    pypi_0    pypi\n",
      "importlib_metadata        7.0.1                hd3eb1b0_0  \n",
      "ipykernel                 6.29.3                   pypi_0    pypi\n",
      "ipython                   8.18.1                   pypi_0    pypi\n",
      "ipywidgets                8.1.2                    pypi_0    pypi\n",
      "isoduration               20.11.0                  pypi_0    pypi\n",
      "jedi                      0.19.1                   pypi_0    pypi\n",
      "jpeg                      9e                   h0b41bf4_3    conda-forge\n",
      "json5                     0.9.24                   pypi_0    pypi\n",
      "jsonpointer               2.4                      pypi_0    pypi\n",
      "jsonschema                4.21.1                   pypi_0    pypi\n",
      "jsonschema-specifications 2023.12.1                pypi_0    pypi\n",
      "jupyter-client            8.6.1                    pypi_0    pypi\n",
      "jupyter-core              5.7.2                    pypi_0    pypi\n",
      "jupyter-events            0.10.0                   pypi_0    pypi\n",
      "jupyter-lsp               2.2.4                    pypi_0    pypi\n",
      "jupyter-server            2.13.0                   pypi_0    pypi\n",
      "jupyter-server-terminals  0.5.3                    pypi_0    pypi\n",
      "jupyter_client            8.6.0            py39h06a4308_0  \n",
      "jupyter_core              5.5.0            py39h06a4308_0  \n",
      "jupyterlab                4.1.5                    pypi_0    pypi\n",
      "jupyterlab-pygments       0.3.0                    pypi_0    pypi\n",
      "jupyterlab-server         2.25.4                   pypi_0    pypi\n",
      "jupyterlab-widgets        3.0.10                   pypi_0    pypi\n",
      "keras                     3.1.1                    pypi_0    pypi\n",
      "kiwisolver                1.4.5                    pypi_0    pypi\n",
      "lame                      3.100             h166bdaf_1003    conda-forge\n",
      "lcms2                     2.15                 hfd0df8a_0    conda-forge\n",
      "ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\n",
      "lerc                      4.0.0                h27087fc_0    conda-forge\n",
      "libblas                   3.9.0            21_linux64_mkl    conda-forge\n",
      "libcblas                  3.9.0            21_linux64_mkl    conda-forge\n",
      "libclang                  18.1.1                   pypi_0    pypi\n",
      "libdeflate                1.17                 h0b41bf4_0    conda-forge\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\n",
      "libgcc-ng                 13.2.0               h807b86a_5    conda-forge\n",
      "libgfortran-ng            13.2.0               h69a702a_5    conda-forge\n",
      "libgfortran5              13.2.0               ha4646dd_5    conda-forge\n",
      "libhwloc                  2.9.3           default_h554bfaf_1009    conda-forge\n",
      "libiconv                  1.17                 hd590300_2    conda-forge\n",
      "liblapack                 3.9.0            21_linux64_mkl    conda-forge\n",
      "liblapacke                3.9.0            21_linux64_mkl    conda-forge\n",
      "libnsl                    2.0.1                hd590300_0    conda-forge\n",
      "libpng                    1.6.43               h2797004_0    conda-forge\n",
      "libsodium                 1.0.18               h7b6447c_0  \n",
      "libsqlite                 3.45.2               h2797004_0    conda-forge\n",
      "libstdcxx-ng              13.2.0               h7e041cc_5    conda-forge\n",
      "libtiff                   4.5.0                h6adf6a1_2    conda-forge\n",
      "libuuid                   2.38.1               h0b41bf4_0    conda-forge\n",
      "libuv                     1.48.0               hd590300_0    conda-forge\n",
      "libwebp-base              1.3.2                hd590300_0    conda-forge\n",
      "libxcb                    1.13              h7f98852_1004    conda-forge\n",
      "libxcrypt                 4.4.36               hd590300_1    conda-forge\n",
      "libxml2                   2.12.6               h232c23b_0    conda-forge\n",
      "libzlib                   1.2.13               hd590300_5    conda-forge\n",
      "llvm-openmp               18.1.1               h4dfa4b3_0    conda-forge\n",
      "llvmlite                  0.42.0                   pypi_0    pypi\n",
      "markdown                  3.6                      pypi_0    pypi\n",
      "markdown-it-py            3.0.0                    pypi_0    pypi\n",
      "markupsafe                2.1.5                    pypi_0    pypi\n",
      "matplotlib                3.8.3                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.6            py39h06a4308_0  \n",
      "mdurl                     0.1.2                    pypi_0    pypi\n",
      "mistune                   3.0.2                    pypi_0    pypi\n",
      "mkl                       2024.0.0         ha957f24_49657    conda-forge\n",
      "mkl-devel                 2024.0.0         ha770c72_49657    conda-forge\n",
      "mkl-include               2024.0.0         ha957f24_49657    conda-forge\n",
      "ml-dtypes                 0.3.2                    pypi_0    pypi\n",
      "mpmath                    1.3.0                    pypi_0    pypi\n",
      "namex                     0.0.7                    pypi_0    pypi\n",
      "nbclient                  0.10.0                   pypi_0    pypi\n",
      "nbconvert                 7.16.2                   pypi_0    pypi\n",
      "nbformat                  5.10.3                   pypi_0    pypi\n",
      "ncurses                   6.4.20240210         h59595ed_0    conda-forge\n",
      "nest-asyncio              1.6.0            py39h06a4308_0  \n",
      "nettle                    3.6                  he412f7d_0    conda-forge\n",
      "nglview                   3.1.2                    pypi_0    pypi\n",
      "notebook                  7.1.2                    pypi_0    pypi\n",
      "notebook-shim             0.2.4                    pypi_0    pypi\n",
      "numba                     0.59.1                   pypi_0    pypi\n",
      "numpy                     1.26.4           py39h474f0d3_0    conda-forge\n",
      "openh264                  2.1.1                h780b84a_0    conda-forge\n",
      "openjpeg                  2.5.0                hfec8fc6_2    conda-forge\n",
      "openssl                   3.2.1                hd590300_1    conda-forge\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\n",
      "optree                    0.10.0                   pypi_0    pypi\n",
      "overrides                 7.7.0                    pypi_0    pypi\n",
      "packaging                 24.0                     pypi_0    pypi\n",
      "pandocfilters             1.5.1                    pypi_0    pypi\n",
      "parso                     0.8.3              pyhd3eb1b0_0  \n",
      "pexpect                   4.9.0                    pypi_0    pypi\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    9.4.0            py39h2320bf1_1    conda-forge\n",
      "pip                       24.0               pyhd8ed1ab_0    conda-forge\n",
      "platformdirs              4.2.0                    pypi_0    pypi\n",
      "prometheus-client         0.20.0                   pypi_0    pypi\n",
      "prompt-toolkit            3.0.43           py39h06a4308_0  \n",
      "protobuf                  4.25.3                   pypi_0    pypi\n",
      "psutil                    5.9.8                    pypi_0    pypi\n",
      "pthread-stubs             0.4               h36c2ea0_1001    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
      "pure_eval                 0.2.2              pyhd3eb1b0_0  \n",
      "pygments                  2.17.2                   pypi_0    pypi\n",
      "pyparsing                 3.1.2                    pypi_0    pypi\n",
      "python                    3.9.19          h0755675_0_cpython    conda-forge\n",
      "python-dateutil           2.9.0.post0              pypi_0    pypi\n",
      "python_abi                3.9                      4_cp39    conda-forge\n",
      "pytorch                   1.10.1          py3.9_cuda11.3_cudnn8.2.0_0    pytorch\n",
      "pytorch-mutex             1.0                        cuda    pytorch\n",
      "pyyaml                    6.0.1                    pypi_0    pypi\n",
      "pyzmq                     25.1.2           py39h6a678d5_0  \n",
      "readline                  8.2                  h8228510_1    conda-forge\n",
      "referencing               0.34.0                   pypi_0    pypi\n",
      "requests                  2.31.0                   pypi_0    pypi\n",
      "rich                      13.7.1                   pypi_0    pypi\n",
      "rpds-py                   0.18.0                   pypi_0    pypi\n",
      "scipy                     1.12.0                   pypi_0    pypi\n",
      "setuptools                69.2.0                   pypi_0    pypi\n",
      "six                       1.16.0             pyhd3eb1b0_1  \n",
      "sniffio                   1.3.1                    pypi_0    pypi\n",
      "stack-data                0.6.3                    pypi_0    pypi\n",
      "stack_data                0.2.0              pyhd3eb1b0_0  \n",
      "sympy                     1.12                     pypi_0    pypi\n",
      "tbb                       2021.11.0            h00ab1b0_1    conda-forge\n",
      "tensorboard               2.16.2                   pypi_0    pypi\n",
      "tensorboard-data-server   0.7.2                    pypi_0    pypi\n",
      "tensorflow                2.16.1                   pypi_0    pypi\n",
      "tensorflow-io-gcs-filesystem 0.36.0                   pypi_0    pypi\n",
      "termcolor                 2.4.0                    pypi_0    pypi\n",
      "terminado                 0.18.1                   pypi_0    pypi\n",
      "tk                        8.6.13          noxft_h4845f30_101    conda-forge\n",
      "tomli                     2.0.1                    pypi_0    pypi\n",
      "torch-scatter             2.1.2                    pypi_0    pypi\n",
      "torchaudio                0.10.1               py39_cu113    pytorch\n",
      "torchvision               0.11.2               py39_cu113    pytorch\n",
      "tornado                   6.4                      pypi_0    pypi\n",
      "tqdm                      4.66.2                   pypi_0    pypi\n",
      "traitlets                 5.14.2                   pypi_0    pypi\n",
      "types-python-dateutil     2.9.0.20240316           pypi_0    pypi\n",
      "typing_extensions         4.10.0             pyha770c72_0    conda-forge\n",
      "tzdata                    2024a                h0c530f3_0    conda-forge\n",
      "uri-template              1.3.0                    pypi_0    pypi\n",
      "urllib3                   2.2.1                    pypi_0    pypi\n",
      "wcwidth                   0.2.13                   pypi_0    pypi\n",
      "webcolors                 1.13                     pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.7.0                    pypi_0    pypi\n",
      "werkzeug                  3.0.1                    pypi_0    pypi\n",
      "wheel                     0.42.0             pyhd8ed1ab_0    conda-forge\n",
      "widgetsnbextension        4.0.10                   pypi_0    pypi\n",
      "wrapt                     1.16.0                   pypi_0    pypi\n",
      "xorg-libxau               1.0.11               hd590300_0    conda-forge\n",
      "xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\n",
      "xz                        5.2.6                h166bdaf_0    conda-forge\n",
      "zeromq                    4.3.5                h6a678d5_0  \n",
      "zipp                      3.18.1                   pypi_0    pypi\n",
      "zlib                      1.2.13               hd590300_5    conda-forge\n",
      "zstd                      1.5.5                hfc55251_0    conda-forge\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d9d58ddb04bb635eba824a3c64b6d0110bcc4c6cff8b192a6f7cbbb2bf10de4"
  },
  "kernelspec": {
   "display_name": "gemnet",
   "language": "python",
   "name": "gemnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
